---
title: "Memoria de Series Temporales"
author: "Enrique Sayas Bailach y Carlos Gila Blanco"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Los dos datasets utilizados han sido descargados desde Kaggle.

El utilizado para la serie temporal con tendencia es [annual_gold_rate](https://www.kaggle.com/datasets/hemil26/gold-rates-1985-jan-2022), que muestra el valor anual del oro desde 1980 hasta 2022 en Dirham de los Emiratos Árabes Unidos.

Por otra parte, el dataset utilizado para la serie temporal con tendencia y estacionalidad es [HospitalityEmployees](https://www.kaggle.com/datasets/gabrielsantello/hospitality-employees-time-series-dataset/data), que muestra el número de empleados en la hostelería en California desde enero de 1990 hasta diciembre de 2018.

# Carga de librerías

```{r}
rm(list=ls())
library(forecast)
library(readr)
library(lubridate)
library(dplyr)
library(ggplot2)
```

# Serie temporal con tendencia

### Importación de los datos

```{r}
gold <- read_csv("Datos/annual_gold_rate.csv", 
    col_types = cols(Date = col_date(format = "%Y-%m-%d")))
```

### Creación de la serie temporal

```{r}
attach(gold)
gold_ts <- ts(AED,start=c(1980),frequency=1)
plot(gold_ts, ylab = "Gold Value (AED)")
```

En base a la evolución temporal del valor del oro, se puede observar que existe una tendencia pero no una estacionalidad.

## Modelo de suavizado exponencial

Por tanto, el mejor modelo de suavizado exponencial será el modelo de Holt.

Las ecuaciones de observación y actualización del modelo son las siguientes:

$$
\hat{x}_t=L_{t-1} + T_{t-1}
$$
$$
L_t = \alpha \cdot x_t + (1-\alpha) \cdot (L_{t-1}+T_{t-1})
$$
$$
T_t = \beta \cdot (L_t-L_{t-1}) + (1-\beta) \cdot T_{t-1}
$$

Ecuación de predicción:

$$
\hat{x}_{n+k} = L_n + k \cdot T_{n}
$$

### Creación del modelo

```{r}
gold_holt <- HoltWinters(gold_ts, gamma = FALSE)
```

### Visualización de los coeficientes y los parámetros

```{r}
gold_holt$coefficients
```

```{r}
gold_holt$alpha
```

```{r}
gold_holt$beta
```

Al ser $\alpha = 1$, sólo se tendrá en cuenta el valor anterior para calcular el nivel del valor siguiente.

A partir de los coeficientes obtenidos calculamos las ecuaciones de actualización:

$$
L_t = x_t
$$
$$
T_t = 0.6672362 \cdot (L_t-L_{t-1}) + (1-0.6672362) \cdot T_{t-1}
$$

Y la ecuación de predicción:

$$
\hat{x}_{n+k} = 6611.71 + k \cdot 141.3085
$$

### Cálculo de la bondad del ajuste

```{r}
fitval_gold <- fitted(gold_holt)
tail(fitval_gold, 10)
```

```{r}
rmse <- sqrt(mean((gold_ts - fitval_gold[,1])^2))
rmse
```

```{r}
mape <- 100*mean(abs(gold_ts-fitval_gold[,1])/gold_ts)
mape
```

A partir del MAPE se puede concluir que se tiene un error medio del 9.89%.

### Representación de la serie real frente a la serie ajustada

```{r}
plot(gold_holt)
```

En el gráfico se puede observar el error medio del 9.89% respecto a la serie original.

### Predicción para h=2

```{r}
pred_gold <- predict(gold_holt,n.ahead=2,prediction.interval=TRUE,level=0.95) 
```

### Representación de la predicción junto a la serie

```{r}
plot(gold_holt, pred_gold)
```

## Modelo ARIMA

### Transformación de la serie (si es necesario) a un proceso estacionario

Como se ha visto previamente, la serie temporal tiene una tendencia creciente por lo que será necesario transformarla a estacionaria. Para saber el número de diferencias necesarias se hará uso de la función ndiffs.

```{r}
ndiffs(gold_ts)
```

ndiffs devuelve que para que sea estacionaria se deberá realizar una diferencia.

```{r}
gold_diff_ts <- diff(gold_ts)
plot(gold_diff_ts)
```

### Representación gráfica e interpretación de la función de autocorrelación y de autocorrelación parcial

```{r}
acf(gold_diff_ts)
```

A partir de la función de autocorrelación, se observa que hay únicamente un valor relevente. De este modo, se puede suponer un MA(1). Sin embargo, se puede considerar que existe un decrecimiento por lo que usaremos también un AR().

```{r}
pacf(gold_diff_ts)
```

Se observa un decrecimiento en la función de autocorrelación parcial, por lo que se puede confirmar el MA(1). Asimismo, se puede considerar que existe únicamente un valor relevante y el resto nulos, entonces se estaría frente a un AR(1).

### Encuentra el modelo ARIMA(p,d,q) que mejor describe la serie y escribe su ecuación

Inicialmente se utilizará el modelo MA(1) con una diferencia:

```{r}
ma.fitted <- arima(gold_ts,order = c(0,1,1))
ma.fitted
```

Modelo AR(1) con una diferencia:
```{r}
ar.fitted <- arima(gold_ts, order = c(1,1,0))
ar.fitted
```
Comparamos los resultados con la función auto.arima

```{r}
auto.arima(gold_ts)
```

Debido a la poca diferencia entre los modelos detectados y el devuelto por la función auto.arima, se empleará el modelo ARIMA(1,1,0).

Ecuación del modelo ARIMA(1,1,0):

$$
\text{Sea} \ Y_t = (1-B)X_t
$$

$$
Y_t = 0.5048Y_{t-1} + \epsilon_t
$$

### Cálculo de la bondad del ajuste

```{r}
accuracy(ar.fitted)
```

En comparación con el modelo de suavizado exponencial, el método ARIMA ofrece un mejor ajuste.

### Representación de la serie real frente a la serie ajustada

```{r}
plot(gold_ts)
lines(fitted(ar.fitted), col = "red")
```

### Cálculo de la predicción para h=2 instantes temporales futuros

```{r}
ar.pred <- predict(ar.fitted,n.ahead=2,prediction.interval=TRUE,level=0.95)
```

### Representación gráfica de la serie junto a la predicción obtenida

```{r}
plot(forecast(ar.fitted,h=2))
```

## Red neuronal autorregresiva no lineal

### Modelo NAR por defecto
```{r}
fit.nar_gold <- nnetar(gold_ts)
fit.nar_gold
```

### Modelo NAR que mejor describe la serie temporal
```{r}
errores_mape_gold <- list()

for (p in 1:7){
  for (k in 1:7){
    fit.nar_g = nnetar(gold_ts, p=p, size=k)
    errores_mape_gold[[paste("p", p, "_size", k)]] <- list(
      p = p,
      size = k,
      mape_nar_g = accuracy(fit.nar_g)[5])
  }
}

best_fit.nar_g <- errores_mape_gold[[which.min(sapply(errores_mape_gold, function(x) x$mape_nar_g))]]

print(best_fit.nar_g)

fit.nar_gold <- nnetar(gold_ts, p = best_fit.nar_g$p, size = best_fit.nar_g$size)
```

Tal y como se podía prever, un valor más alto de p y de k proporciona un error menor.

### Cálculo de la bondad del ajuste
```{r}
accuracy(fit.nar_gold)
```

### Representación de la serie real frente a la ajustada
```{r}
fitval_nar_gold <- fitted.values(fit.nar_gold)

plot(gold_ts,xlab="Año",ylab="Precio")
lines(fitval_nar_gold, col="blue")
abline(v=95)
```

Se ve un ajuste muy preciso conforme avanza la serie, que se debe a un posible sobreajuste debido a la utilización de valores de p y k demasiado elevados. En consecuencia, este modelo es el que realiza un mejor ajuste respecto a los modelos de suavizado exponencial y ARIMA. 

### Predicción y representación para h=2 instantes temporales futuros
```{r}
pred <- forecast(fit.nar_gold, PI = TRUE, h=2)
plot(pred)
```

# Serie temporal con tendencia + estacionalidad

### Importación y Adecuación de la serie

```{r}
HospitalityEmployees <- read_csv("Datos/HospitalityEmployees.csv")
HospitalityEmployees$Date <- as.Date(HospitalityEmployees$Date, format = "%m/%d/%Y")
HospitalityEmployees$Employees <- floor(HospitalityEmployees$Employees)
```

### Representación de la serie temporal

```{r}
attach(HospitalityEmployees)
HospitalityEmployees_ts <- ts(Employees,start=c(1990,1),end=c(2018,12),frequency=12)
HospEmp2010_ts <- window(HospitalityEmployees_ts, start = c(2010,1))
plot(HospEmp2010_ts, ylab = "Hospitality Employees")
```

### Descripción de la serie

```{r}
plot(decompose(HospEmp2010_ts, type="additive"))
```

En base a la evolución temporal del número de empleados en la hostelería, se puede observar que existe una tendencia y una estacionalidad.

## Modelo Holt-Winters

### Comparación de los modelos

Modelo Holt-Winters con estacionalidad aditiva

```{r}
emp_ad <- HoltWinters(HospEmp2010_ts, seasonal = "additive")
fit_emp_ad <- fitted(emp_ad)

#RMSE
rmse_ad <- sqrt(mean((HospEmp2010_ts - fit_emp_ad[,1])^2))
rmse_ad

#MAPE
mape_ad <- 100*mean(abs(HospEmp2010_ts-fit_emp_ad[,1])/HospEmp2010_ts)
mape_ad
```

Modelo Holt-Winters con estacionalidad multiplicativa

```{r}
emp_mult <- HoltWinters(HospEmp2010_ts, seasonal = "multiplicative")
fit_emp_mult <- fitted(emp_mult)

#RMSE
rmse_mult <- sqrt(mean((HospEmp2010_ts - fit_emp_mult[,1])^2))
rmse_mult

#MAPE
mape_mult <- 100*mean(abs(HospEmp2010_ts-fit_emp_mult[,1])/HospEmp2010_ts)
mape_mult
```

Comparación entre los modelos Holt-Winters aditivo y multiplicativo en base a los errores RMSE y MAPE

$$
\begin{tabular}{| c | c | c |}
\hline
    Holt-Winters & RMSE & MAPE \\ \hline
    Additive & 6.192158 & 0.2809599\\ \hline
    Multiplicative & 5.668459 & 0.2562788 \\ \hline
\end{tabular} 
$$
El mejor modelo de suavizado exponencial será el modelo de Holt-Winters con estacionalidad aditiva pues la diferencia en el RMSE entre ambos modelos es muy pequeña, siendo más fácil la implementación del modelo con estacionalidad aditiva.

Las ecuaciones de observación y actualización del modelo son las siguientes:

$$
\hat{x}_t = L_{t-1} + T_{t-1} + S_{t-c}
$$

$$
L_t = \alpha \cdot (x_{t}-S_{t-c}) + (1-\alpha) \cdot (L_{t-1} + T_{t-1})
$$
$$
T_t = \beta \cdot (L_t - L_{t-1}) + (1 - \beta) \cdot T_{t-1}
$$

$$
S_t = \gamma \cdot (x_t - L_t) + (1 - \gamma) \cdot S_{t-c}
$$

Y la ecuación de predicción:

$$
\hat{x}_{n+k} = L_n + k\cdot T_n + S_{n+k-c}
$$

### Creación del modelo

```{r}
emp_fit <- HoltWinters(HospEmp2010_ts, seasonal = "additive")
```

### Visualización de los coeficientes y los parámetros

```{r}
emp_fit$coefficients
```

```{r}
emp_fit$alpha
```

```{r}
emp_fit$beta
```

```{r}
emp_fit$gamma
```

Al ser $\beta = 0.055$, la tendencia es constante y como $\gamma = 1$, el efecto estacional varía de año en año, y por tanto su actualización depende sólo del efecto estacionado en dicho instante, sin tener en cuenta el efecto estacional del año anterior.

A partir de los coeficientes obtenidos calculamos las ecuaciones de actualización:

$$
L_t = 0.6583277 \cdot (x_t - S_{t-12}) + (1-0.6583277) \cdot(L_{t-1} + T_{t-1})
$$
$$
T_t = 0.05505944 \cdot (L_t-L_{t-1}) + (1-0.05505944) \cdot T_{t-1}
$$
$$
S_t = x_t - L_t
$$

Y la ecuación de predicción

$$
\hat{x}_{n+k} = 2009.266255 + k \cdot 4.174587 + S_{n+k-12}
$$

### Cálculo de la bondad del ajuste

```{r}
cat("RMSE:",rmse_ad)
cat("\nMAPE:",mape_ad)
```

```{r}
fitval_emp <- fitted(emp_fit)
tail(fitval_emp, 10)
```


### Representación de la serie real frente a la serie ajustada

```{r}
plot(emp_fit)
```

### Predicción para h=c

```{r}
pred_hosp <- predict(emp_fit,12)
pred_hosp
```

### Representación de la predicción junto a la serie

```{r}
pred <- predict(emp_fit,n.ahead=12,prediction.interval=TRUE,level=0.95) 

plot(emp_fit, pred)
```

## Modelo sARIMA

### Transformación de la serie hasta llegar a un proceso estacionario

Como se ha visto anteriormente, se está frente a una serie temporal con estacionalidad con frecuencia igual a 12 y tendencia.

De este modo, se aplicará una diferencia estacional.

$$
\nabla_{12} x_t = x_t-x_{t-12}
$$

```{r}
HospEmp2010_12_ts <- diff(HospEmp2010_ts,12)
plot(HospEmp2010_12_ts)
```

Asimismo, se deberá realizar otra diferencia para eliminar la tendencia.

```{r}
ndiffs(HospEmp2010_12_ts)
```

```{r}
HospEmp2010_12_ts <- diff(HospEmp2010_12_ts,1)
plot(HospEmp2010_12_ts)
```

### Representación gráfica e interpretación de la función de autocorrelación y de autocorrelación parcial

```{r}
acf(HospEmp2010_12_ts,lag.max = 48)
```

A partir de la función de correlación, se observa que existe un decrecimiento en la parte regular, por lo que se estaría ante un AR(). Sin embargo, también se puede interpretar que existe únicamente un coeficiente no nulo, lo que sería un MA(1).

Por otro lado, respecto a la parte estacional, se encuentra un coeficiento no nulo, entonces tendremos un posible MA(1).

```{r}
pacf(HospEmp2010_12_ts, lag.max = 48)
```

En base a la función de correlación parcial, se atisba en la parte regular un coeficiente no nulo por lo que se corresponde al AR(1). No obstante, también se puede considerar el decrecimiento correspondiente al MA(1).

Respecto a la parte estacional, se confirma el MA(1) pues se tiene un decrecimiento.

De este modo, se tendrán como modelos a comprobar sARIMA(1,1,0)(0,1,1) y sARIMA(0,1,1)(0,1,1).

### Obtención del modelo sARIMA que mejor describe la serie y su ecuación.

Inicialmente se modelizará el sARIMA(1,1,0)(0,1,1):

```{r}
sarima1.fitted <- arima(HospEmp2010_ts, order = c(1,1,0),seasonal = list(order = c(0,1,1)))
sarima1.fitted
```

Creación del sARIMA(0,1,1)(0,1,1)

```{r}
sarima2.fitted <- arima(HospEmp2010_ts, order = c(0,1,1),seasonal = list(order = c(0,1,1)))
sarima2.fitted
```

Utilizamos auto.arima para comparar el modelo devuelto con los encontrados previamente.

```{r}
auto.arima(HospEmp2010_ts)
```
El modelo que se utilizará de ahora en adelante es el sARIMA(1,1,0)(0,1,1) pues es el que tiene mejor AIC y coincide con el devuelto por auto.arima.

La ecuación siguiente es la correspondiente a la sARIMA(1,1,0)(0,1,1):

$$
\text{Sea} \ Y_t = (1-B^{12})(1-B)X_t
$$

$$
(1-\phi_1B)Y_t = (1-\Theta_1B^{12})\epsilon_t
$$

Sustituyendo los valores:

$$
(1+0.1644B)Y_t = (1-0.4680B^{12})\epsilon_t
$$

### Cálculo de la bondad del ajuste

```{r}
accuracy(sarima1.fitted)
```

En comparación con el modelo de suavizado exponencial, el método ARIMA ofrece un mejor ajuste.

### Representación de la serie real frente a la serie ajustada

```{r}
plot(HospEmp2010_ts)
lines(fitted(sarima1.fitted), col = "red")
```

### Cálculo de la predicción para h=c instantes temporales futuros

```{r}
sarima1.pred <- predict(sarima1.fitted,n.ahead=12,prediction.interval=TRUE,level=0.95)
sarima1.pred
```

### Representación gráfica de la serie junto a la predicción obtenida

```{r}
plot(forecast(sarima1.fitted,h=12))
```

## Red neuronal autorregresiva no lineal

### Modelo NAR por defecto
```{r}
fit.nar_emp <- nnetar(HospEmp2010_ts)
fit.nar_emp
```

### Modelo NAR que mejor describe la serie temporal
```{r}
errores_mape_emp <- list()

for (p in 1:10){
  for (P in 1:8){
    for (k in 1:10){
      fit.nar_e = nnetar(HospEmp2010_ts, p=p, P=P, size=k)
      errores_mape_emp[[paste("p", p, "P", P, "_size", k)]] <- list(
        p = p,
        P = P,
        size = k,
        mape_nar_e = accuracy(fit.nar_e)[5])
    }
  }
}

best_fit.nar_e <- errores_mape_emp[[which.min(sapply(errores_mape_emp, function(x) x$mape_nar_e))]]

print(best_fit.nar_e)

fit.nar_emp <- nnetar(HospEmp2010_ts, p = best_fit.nar_e$p, P = best_fit.nar_e$P, size = best_fit.nar_e$size)
```

En este caso también se observa que, a nivel general, valores mayores de los distintos parámetros proporcionan un mejor ajuste. Así pues, en correspondencia con lo visto en la serie con tendencia, el modelo NAR realiza un mejor ajuste que los modelos de suavizado exponencial y ARIMA.

### Cálculo de la bondad del ajuste
```{r}
accuracy(fit.nar_emp)
```

### Representación de la serie real frente a la ajustada
```{r}
fitval_nar_emp <- fitted.values(fit.nar_emp)

plot(HospEmp2010_ts,xlab="Año",ylab="Empleados")
lines(fitval_nar_emp, col="blue")
abline(v=95)
```

### Predicción y representación para h=c instantes temporales futuros
```{r}
pred <- forecast(fit.nar_emp, PI = TRUE, h=12)
plot(pred)
```

